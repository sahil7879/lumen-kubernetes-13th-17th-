```

16th :
    
    k get deploy -n kube-system
 1524  clear
 1525  k get pods
 1526  k run ramanapp --image httpd
 1527  k run ramanapp2 --image nginx
 1528  k get pods
 1529  k create deploy dep1 --image httpd --replicas 5
 1530  clear
 1531  k get pods
 1532  k get pods -A
 1533  clear
 1534  k get all -A
 1535* 
 1536  ls
 1537  cat allresource.yaml 
 1538  clear
 1539  k get pods
 1540  clear
 1541  k get pods
 1542  k get pods -A
 1543  ifconfig
 1544  clear
 1545  ps -ef | grep kubelet
 1546  cat /var/lib/kubelet/config.yaml
 1547  cd /etc/kubernetes/manifests
 
 

BACKUP : = etcd backup 


export ETCDCTL_API=3

apt  install etcd-client

etcdctl --endpoints=https://127.0.0.1:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key snapshot save /root/clusterbak.db


----------

--- delete all pods : application failiure
..


BACKUP :
    
   data-directory : etcd 
   
   original :
       
   ps -ef | grep data
 1576  cd /var/lib/etcd
 1577  ls
 1578  cd member/
 1579  ls
 1580  cd snap/


------ restore ur backp now :
    
    etcdctl --data-dir /var/lib/etcd-new snapshot restore /root/clusterbak.db
    
    
    

ls
 1582  cd ..
 1583  ls
 1584  cd ..
 1585  ls
 1586  cd ..
 1587  ls
 1588  history
 1589  vi /etc/kubernetes/manifests/etcd.yaml 
 1590  k get pods
 1591  ls
 1592  ls etcd*
 1593  ls | grep etcd
 1594  etcdctl --data-dir /var/lib/etcd-new snapshot restore /root/clusterbak.db
 1595  ls | grep etcd
 1596  cd etcd-new
 1597  ls
 1598  cd member/
 1599  ls
 1600  cd snap/
 1601  ls
 1602  k get pods
 1603  ps -ef | grep data
 1604  vi /etc/kubernetes/manifests/etcd.yaml 
 1605  clear
 1606  k get pods
 1607  crictls pa
 1608  crictls ps
 1609  crictl ps
 1610  clear
 1611  k get pods
 1612  crictl ps --watch
 1613  crictl ps --latest
 1614  clear
 1615  crctl ps
 1616  crictl ps
 1617  clear
 1618  k g
 1619  k get pods
 1620  ps -ef | data
 1621  ps -ef | grep data
 1622  clear
 1623  k get pods
 1624  history

    
    

==============================================================================================


node mntennce operations :
   
   w1 >> w2 
    
    drain 
    
    cordon 
    uncordon
    
    
    
    k get nodes
 1637  k cordon w1
 1638  k get pods -o wide
 1639  k drain w1
 1640  k describe node master
 1641  k describe node w1| grep taint
 1642  k describe node w1| grep -i taint
 1643  k describe node w2| grep -i taint
 1644  k drain w1
 1645  k get daemonsets
 1646  k get daemonsets -n kube-system
 1647  clear
 1648  k drain w1 
 1649  k drain w1 --ignore-daemonsets
 1650  k get pods
 1651  k drain w1 --ignore-daemonsets --force 
 1652  k get pods -o wide
 1653  k get pods -A
 1654  clear
 1655  k get pods
 1656  k get nodes
 1657  k get pods -A -o wide
 1658  clear



after mntennce >  uncordon w1


k uncordon w1
 1661  clear
 1662  k describe nodes | grep -i taint
 1663  clear
 1664  k get nodes
 1665  k get pods -o wide
 1666  k get nodes
 1667  k create deploy depw11 --image httpd --replicas 5
 1668  k create deploy depw11 --image nginx --replicas 5
 1669  k create deploy depw12 --image nginx --replicas 5
 1670  clear
 1671  k get pods -o wide
 1672  k cordon w1
 1673  k get nodes
 1674  k get pods -o wide
 1675  k drain w1 --ignore-daemonsets --force 
 1676  k get pods -o wide
 1677  k get pods -o wide -A
 1678  clear
 1679  k get pods -o wide
 1680  k get deploy
 1681  k create deploy depw3 --image nginx --replicas 5
 1682  k get pods -o wide
 1683  k uncordon w1
 1684  k get pods -o wide
 1685  k create deploy depw4 --image nginx --replicas 2
 1686  k get pods -o wide
 1687  k get nodes
 
 
 ===================================================================================

health-checks :
    
    
    
    root@master:~# cat liveliness.yml 

apiVersion: apps/v1
kind: Deployment
metadata:
  name: mongo
spec:
  replicas: 3
  selector:
    matchLabels:
      app: mongo
  template:
    metadata:
      labels:
        app: mongo
    spec:
      containers:
        - name: mongo
          image: mongo:4.0.8
          livenessProbe:
            exec:
              command:
                - mongo
                - --eval
              # - "db.adminCommand('ping')"
                - "db1.adminCommand('ping')" 
            initialDelaySeconds: 1
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 2


----------------------------

Readiness probe :

-- start from incorret command 
-- this removes pod from svc endpoint .


root@master:~# cat readiness.yml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mongo
spec:
  replicas: 3
  selector:
    matchLabels:
      app: mongo
  template:
    metadata:
      labels:
        app: mongo
    spec:
      containers:
        - name: mongo
          image: mongo:4.0.8
          readinessProbe:
            exec:
              command:
                - mongo
                - --eval
              #  - "db.adminCommand('ping')"
                - "db1.adminCommand('ping')" 
            initialDelaySeconds: 1
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 2
---
apiVersion: v1
kind: Service
metadata:
  name:  mongodb-service
spec:
  selector:
    app: mongo
  ports:
  - protocol:  TCP
    port:  27017
    targetPort:  27017




history :
    
    
    k logs -f dep1-7fd854dc89-486sd
 1701  k get pods
 1702  systemctl status kubelet
 1703  k get pods
 1704  clear
 1705  ls
 1706  k get pods
 1707  cat /etc/kubernetes/manifests/etcd.yaml 
 1708  cat /etc/kubernetes/manifests/kube-apiserver.yaml 
 1709  clear
 1710  ls
 1711  k delete deploy --all
 1712  k get pods
 1713  k get pods 
 1714  k delete deploy --all
 1715  k delete deploy dep1
 1716  clear
 1717  k get pods -o wide
 1718  k get all -A
 1719  clear
 1720  k get pods
 1721  clear
 1722  ls
 1723  cd ramanyamlfiles/
 1724  ls
 1725  vi liveliness.yml
 1726  k create -f liveliness.yml 
 1727  k get pods --watch
 1728  clear
 1729  k get pods
 1730  vi liveliness.yml 
 1731  k apply -f liveliness.yml 
 1732  k get pods
 1733  k delete deploy --all 
 1734  clear
 1735  k get pods
 1736  clear
 1737  vi readiness.yml
 1738  k create -f readiness.yml 
 1739  k get pods
 1740  k describe svc
 1741  clear
 1742  k get pods
 1743  k describe svc mongodb-service
 1744  k get ep
 1745  k get pods
 1746  vi readiness.yml 
 1747  k apply -f readiness.yml 
 1748  clear
 1749  k get pods
 1750  k describe svc mongodb-service
 
 ==========================================



cicd :
    

    
    pipeline : workflow 
    github >> dockerfile >> custom image >> conatiner, pod >>(deloymnt)
    
    
    
    
    jenkins installation...
    
    https://pkg.jenkins.io/debian-stable/
    
    http://54.173.189.204:8080/
    raman.,raman
    


-- created a project : raman-project

installed docker


--first stage : buil d a custom image : installing docker plugin


create ur own repo on dockerhub :


=====


copied my .kube/config file and saved on my desktop

i uploaded to to created a conn to kuebretes


https://github.com/ramannkhanna2/nodejsapp_jenkins-docker-kubernetes.git

===========================================================================================

```
