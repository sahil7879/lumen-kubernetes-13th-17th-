HPA :

```


k api-resources
  697  clear
  698  k get pods
  699  top nodes
  700  top pods
  701  clear
  702  k get pods -A
  703  clear
  704  k get pods -n kube-system
  705  git clone https://github.com/ramannkhanna2/k8s_metrics_server.git
  706  ls
  707  cd k8s_metrics_server/
  708  ls
  709  cd deploy/
  710  ls
  711  cd 1.8+/
  712  ls
  713  kubectl apply -f .
  714  clear
  715  k get pods -n kube-system
  716  clear
  717  k get pods -n kube-system
  718  clear
  719  k get deploy
  720  k top nodes
  721  k top pods
  722  clear
  723  k delete deploy --all
  724  k get pods
  725  cd /root/ramanyamlfiles/
  726  vi deploy.yml
  727  cat deploy.yml
  728  k create -f deploy.yml
  729  k get deploy
  730  k top deploy
  731  k top pods
  732  k autoscale deployment httpd-deployment --cpu percent 60 --min=1 --max=5
  733  k autoscale deployment httpd-deployment --cpu-percent 60 --min=1 --max=5
  734  k get hpa
  735  vi deploy.yml
  736  k apply -f deploy.yml
  737  clear
  738  k get hpa
  739  k get pods
  740  k get hpa
  741  k delete hpa
  742  k delete hpa httpd-deployment
  743  k autoscale deployment httpd-deployment --cpu-percent 60 --min=1 --max=5
  744  k get hpa
  745  clear
  746  k get hpa







root@master:~/ramanyamlfiles# cat deploy.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: httpd-deployment
  labels:
    app: httpd
spec:
  replicas: 1
  selector:
    matchLabels:
      app: canary
  template:
    metadata:
      labels:
        app: canary
    spec:
      containers:
      - name: httpd
        image: httpd
        resources:
          requests:
            memory: "64Mi"
            cpu: "250m"
          limits:
            memory: "128Mi"
            cpu: "500m"
        ports:
        - containerPort: 80





 k create -f deploy.yml
  904  k get deploy
  905*
  906  k get hpa
  907  k get hpa -o yaml
  908  clear
  909  k get hpa
  910  k get hpa --watch
  911  clear
  912  k get hpa --watch



```

ROLLOUT :


```



100 pods 
125 max

25(old pods)+75 pods(old pods)+25(newpods)
25(oldpods)+(50oldpods+25new ones)+25newpods







revison1 :

nginx 1.14.1 : v1

deptest 
deptest-66fb6d8ddc
deptest-66fb6d8ddc-45hv8 (20)


k describe deploy | grep -i image


revision2:

1.14.2

deptest
deptest-65d4566f96
deptest-65d4566f96-59tg6  (20)


k describe deploy | grep -i image


revision 3:

latest

deptest
deptest-785cd74f9

current : rev3 >> rev 1 














k get deploy
  918  k get deploy -o yaml
  919  clear
  920  k rollout -g
  921  k rollout -h
  922  cleat
  923  clear
  924  k rollout -h
  925  clear
  926  k delete deploy --all
  927  k get pods
  928  ls
  929  vi deploy.yml
  930  ls
  931  kubectl rollout status deployment
  932  cat deploy.yml
  933  clear
  934  k create -f deploy.yml
  935  kubectl rollout status deployment
  936  k get pods
  937  k delete -f deploy.yml
  938  clear
  939  vi deploy.yml
  940  k get pods
  941  clear
  942  k create -f deploy.yml
  943  kubectl rollout status deployment deptest
  944  vi deploy.yml
  945  k apply -f deploy.yml
  946* kubectl rollout status deployme
  947  clear
  948  kubectl rollout status deployment deptest
  949  kubectl rollout history deploy deptest
  950  k delete deploy --all
  951  clear
  952  k create -f deploy.yml --record=true
  953  kubectl rollout status deployment deptest
  954  kubectl rollout history deploy deptest
  955  k get deploy
  956  k get rs
  957  k get pods
  958  vi deploy.yml
  959  clear
  960  k apply -f deploy.yml --record=true
  961  kubectl rollout status deployment deptest
  962  k edit deploy deptest
  963  k get pods
  964  kubectl rollout history deploy deptest
  965  k get deploy
  966  k get rs
  967  k get pods
  968  k describe deploy | grep image
  969  k describe deploy | grep -i image
  970  vi deploy.yml
  971  k get deploy -o yaml
  972  vi deploy.yml
  973  clear
  974  k create -f deploy.yml
  975  kubectl rollout status deployment deptest
  976  vi deploy.yml
  977  k apply -f deploy.yml --record=true
  978  kubectl rollout status deployment deptest
  979  clear
  980  k rollout history deploy deptest
  981  k get deploy
  982  k get rs
  983  k describe deploy | grep -i image
  984  k rollout undo deploy deptest --to-revision 1
  985  k get rs
  986  k describe deploy | grep -i image
  987  k rollout undo deploy deptest --to-revision 2
  988  k describe deploy | grep -i image
  989  k get rs









root@master:~/ramanyamlfiles# cat deploy.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: deptest
  labels:
    app: httpd
spec:
  replicas: 20
  selector:
    matchLabels:
      app: canary
  #strategy:
    #type: Recreate
  template:
    metadata:
      labels:
        app: canary
    spec:
      containers:
      - name: nginx
        #image: nginx:1.14.1
        # image: nginx:1.14.2
        image: nginx:latest
        ports:
        - containerPort: 80


```

KUBE-DASHBOARD , RBAC, SECRET TOKEN :

```

helm
 1022  curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
 1023  chmod 700 get_helm.sh
 1024  ./get_helm.sh
 1025  helm
 1026  clear
 1027  k get pods -A
 1028  clear
 1029  # Add kubernetes-dashboard repository
 1030  helm repo add kubernetes-dashboard https://kubernetes.github.io/dashboard/
 1031  # Deploy a Helm Release named "kubernetes-dashboard" using the kubernetes-dashboard chart
 1032  helm upgrade --install kubernetes-dashboard kubernetes-dashboard/kubernetes-dashboard --create-namespace --namespace kubernetes-dashboard
 1033  k get pods
 1034  k get ns
 1035  clear
 1036  k get all -n kubernetes-dashboard
 1037  k edit svc -n kubernetes-dashboard
 1038  k edit svc kubernetes-dashboard-kong-proxy  -n kubernetes-dashboard
 1039  k get svc -n kubernetes-dashboard
 1040  k describe pod kubernetes-dashboard-kong-proxy   -n kubernetes-dashboard
 1041  clear
 1042  k get sa -n kubernetes-dashboard
 1043  k describe sa -n kubernetes-dashboard
 1044  clear
 1045  k get sa -n kubernetes-dashboard
 1046  k describe sa -n kubernetes-dashboard kubernetes-dashboard-web
 1047  k describe roles -n kubernetes-dashboard
 1048  clear
 1049  k get sa -n kubernetes-dashboard
 1050  k get roles -n kubernetes-dashboard
 1051  k describe role kubernetes-dashboard-web -n kubernetes-dashboard
 1052  k get rolebinding -n kubernetes-dashboard
 1053  k get rolebinding kubernetes-dashboard-web  -n kubernetes-dashboard
 1054  k describe rolebinding kubernetes-dashboard-web  -n kubernetes-dashboard
 1055  k get secrets -n kubernetes-dashboard
 1056  k get sa -n kubernetes-dashboard
 1057  k edit role kubernetes-dashboard-web -n kubernetes-dashboard
 1058  kubectl -n kubernetes-dashboard create token kubernetes-dashboard-web
 1059  k get secrets -n kubernetes-dashboard
 1060  k describe secret -n kubernetes-dashboard kubernetes-dashboard-csrf
 1061  clear
 1062  ls
 1063  vi admin.yml
 1064  ls
 1065  k create -f admin.yml
 1066  k get sa -n kubernetes-dashboard
 1067  k describe sa admin-user -n kubernetes-dashboard
 1068  kubectl -n kubernetes-dashboard create token admin-user
 1069  clear
 1070  k get clusterrole
 1071  clear
 1072  k describe  clusterrole cluster-admin
 1073  vi clusterrolebinding.yml
 1074  k create -f clusterrolebinding.yml
 1075  k get sa -n kubernetes-dashboard
 1076  k describe  sa kubernetes-dashboard-web -n kubernetes-dashboard
 1077  cat clusterrolebinding.yml
 1078  k get clusterrolebinding | grep admin
 1079  kubectl -n kubernetes-dashboard create token admin-user
 1080  clear
 1081  kubectl -n kubernetes-dashboard create token admin-user
 1082  k get pods -n kubernetes-dashboard
 1083  k get svc -n kubernetes-dashboard
 1084  kubectl -n kubernetes-dashboard create token admin-user
 1085  k get sa -n kubernetes-dashboard







root@master:~/ramanyamlfiles# cat admin.yml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: admin-user
  namespace: kubernetes-dashboard
root@master:~/ramanyamlfiles# cat clusterrolebinding.yml
apiVersion: rbac.authorization.k8s.io/v1



kind: ClusterRoleBinding
metadata:
  name: admin-user
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: admin-user
  namespace: kubernetes-dashboard




```

PV-PVC :

```
https://github.com/ramannkhanna2/Azure-kubernetes-PV-PVC-fileshare.git


clear
 1118  vi hostpathvol.yml
 1119  k create -f hostpathvol.yml
 1120  k get pods -o wide
 1121  cat hostpathvol.yml
 1122  k exec -it redispod -- /bin/bash
 1123  vi hostpathvol.yml
 1124  k create -f hostpathvol.yml
 1125  vi hostpathvol.yml
 1126  k create -f hostpathvol.yml
 1127  k get pods
 1128  k exec -it redispo1d -- /bin/bash
 1129  k exec -it redispod1 -- /bin/bash
 1130  k delete pods --all
 1131  clear
 1132  kubectl create secret generic azure-secret --from-literal=azurestorageaccountname="ramansa" --from literal=azurestorageaccountkey=""
 1133  kubectl create secret generic azure-secret --from-literal=azurestorageaccountname="ramansa" --from-literal=azurestorageaccountkey=""
 1134  k get secrets
 1135  k describe secret
 1136  ls
 1137  vi pv.yaml
 1138  k create -f pv.yaml
 1139  k get pv
 1140  k getpvc
 1141  k get pvc
 1142  vi pvc.yaml
 1143  vi pvc.yaml
 1144  k create -f pvc.yaml
 1145  k get pv
 1146  k get pvc
 1147  clear
 1148  vi pvpod.yaml
 1149  k get pvc
 1150  vi pvpod.yaml
 1151  k get pv
 1152  k get pvc
 1153  k get pods
 1154  k delete deploy --all
 1155  k create -f pvpod.yaml
 1156  k get pods
 1157  k logs -f mypod
 1158  k get pods
 1159  clear
 1160  k get pods
 1161  k get secrets
 1162  k get pods
 1163  k delete secret azure-secret
 1164  kubectl create secret generic azure-secret --from-literal azurestorageaccountname=ramansa --from literal azurestorageaccountkey=
 1165  kubectl create secret generic azure-secret --from-literal azurestorageaccountname=ramansa --from-literal azurestorageaccountkey=
 1166  clear
 1167  k get secrets
 1168  k get pods
 1169  k delete pods --all
 1170  k create -f pvpod.yaml
 1171  k get pods --watch
 1172  k get pods
 1173  k logs -f mypod
 1174  k get pods
 1175  cat pvpod.yaml
 1176  k get pods









root@master:~/ramanyamlfiles# cat hostpathvol.yml
apiVersion: v1
kind: Pod
metadata:
  name: redispod1
  namespace: default
spec:
  restartPolicy: Never
  volumes:
  - name: vol
    hostPath:
      path: /home/ubuntu
  containers:
  - name: redis
    image: "redis"
    volumeMounts:
    - name: vol
      mountPath: /hostfile
  nodeName: w1





root@master:~/ramanyamlfiles# cat pv.yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: azurefile
spec:
  capacity:
    storage: 5Gi
  accessModes:
    - ReadWriteMany
  azureFile:
    secretName: azure-secret
    shareName: test-share
    readOnly: false






root@master:~/ramanyamlfiles# cat pvc.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: azurefileclaim
spec:
  accessModes:
    - ReadWriteMany
  storageClassName: ""
  resources:
    requests:
      storage: 5Gi





root@master:~/ramanyamlfiles# cat pvpod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: mypod
spec:
  containers:
  - image: centos:7
    name: mypod
    volumeMounts:
      - name: rk
        mountPath: /lumen
    command: ["/bin/bash"]
    tty: true
  volumes:
  - name: rk
    persistentVolumeClaim:
      claimName: azurefileclaim



```



```

 git clone https://github.com/ramannkhanna2/kubernetes_end2end_front-backend.git
 1188  ls
 1189  cd kubernetes_end2end_front-backend/
 1190  ls
 1191  k create ns mongo
 1192  k create -f . -n mongo
 1193  clear
 1194  k get all -n mongo
 1195  k logs -f mongodb-deployment-57b7fcfdbb-hhp5l
 1196  k logs -f mongodb-deployment-57b7fcfdbb-hhp5l -n mongo

```
